# Monta o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Instala as bibliotecas necess√°rias e Importa√ß√µes principais
!pip install torchvision segmentation-models-pytorch kagglehub --quiet


import zipfile, os
import numpy as np
import torch
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from torchvision.models.segmentation import fcn_resnet50
import matplotlib.pyplot as plt
import kagglehub
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from matplotlib import colors

# Define dispositivo para rodar em cpu
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Rodando em:", device)

# Caminho do ZIP e extra√ß√£o
zip_path = '/content/drive/MyDrive/Cityscapes/archive.zip'
extract_path = '/content/drive/MyDrive/Cityscapes'

if os.path.exists(zip_path) and not os.path.exists(os.path.join(extract_path, 'cityscapes')):
    print(f"Descompactando {zip_path} para {extract_path}...")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("Arquivo descompactado com sucesso!")
else:
    print("Arquivo zip j√° descompactado ou n√£o encontrado.")

# Baixa o dataset do Kaggle Hub
path = kagglehub.dataset_download("shuvoalok/cityscapes")
print("Dataset baixado em:", path)

# localiza as pastas corretas com os treinos e testes
def detectar_estrutura(base_path):
    if os.path.exists(os.path.join(base_path, "train")):
        train_img_dir = os.path.join(base_path, "train", "img")
        train_mask_dir = os.path.join(base_path, "train", "label")
        val_img_dir = os.path.join(base_path, "val", "img")
        val_mask_dir = os.path.join(base_path, "val", "label")
        print("‚û°Ô∏è Usando estrutura nova (train/img)")
    else:
        leftImg8bit_path, gtFine_path = None, None
        for root, dirs, files in os.walk(base_path):
            if 'leftImg8bit' in dirs:
                leftImg8bit_path = os.path.join(root, 'leftImg8bit')
            if 'gtFine' in dirs:
                gtFine_path = os.path.join(root, 'gtFine')
        if leftImg8bit_path is None or gtFine_path is None:
            raise FileNotFoundError("N√£o foi poss√≠vel encontrar a estrutura de pastas.")
        train_img_dir = os.path.join(leftImg8bit_path, "train")
        train_mask_dir = os.path.join(gtFine_path, "train")
        val_img_dir = os.path.join(leftImg8bit_path, "val")
        val_mask_dir = os.path.join(gtFine_path, "val")
        print("‚û°Ô∏è Usando estrutura antiga (leftImg8bit/gtFine)")
    return train_img_dir, train_mask_dir, val_img_dir, val_mask_dir

train_img_dir, train_mask_dir, val_img_dir, val_mask_dir = detectar_estrutura(path)

# Dataset
class CityscapesDataset(Dataset):
    def __init__(self, image_dir, mask_dir, img_size=(256, 512)):
        self.image_paths = sorted([
            os.path.join(image_dir, f)
            for f in os.listdir(image_dir)
            if f.endswith(('.png', '.jpg'))
        ])[:100]  # Redu√ß√£o para velocidade
        self.mask_paths = sorted([
            os.path.join(mask_dir, f)
            for f in os.listdir(mask_dir)
            if f.endswith(('.png', '.jpg'))
        ])[:100]
        self.img_size = img_size
        self.image_transform = T.Compose([
            T.Resize(self.img_size),
            T.ToTensor(),
            T.Normalize(mean=[0.5]*3, std=[0.5]*3)
        ])
        self.mask_transform = T.Compose([
            T.Resize(self.img_size, interpolation=T.InterpolationMode.NEAREST)
        ])
        self.class_map = self._build_class_map()
        self.num_classes = len(self.class_map)

    def _build_class_map(self):
        ids = [7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33]
        return {id_val: idx for idx, id_val in enumerate(sorted(ids))}

    def map_mask(self, mask):
        mask_out = np.ones_like(mask, dtype=np.uint8) * 255
        for id_val, idx in self.class_map.items():
            mask_out[mask == id_val] = idx
        return mask_out

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        mask = Image.open(self.mask_paths[idx])
        mask = np.array(mask)
        if mask.ndim == 3:
            mask = mask[:, :, 0]
        image = self.image_transform(image)
        mask = self.mask_transform(Image.fromarray(mask))
        mask = self.map_mask(np.array(mask))
        return image, torch.tensor(mask, dtype=torch.long)

# Cria as inst√¢ncias 
train_dataset = CityscapesDataset(train_img_dir, train_mask_dir)
val_dataset = CityscapesDataset(val_img_dir, val_mask_dir)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)

print(f"Total treino: {len(train_dataset)} | valida√ß√£o: {len(val_dataset)}")
print(f"N√∫mero de classes: {train_dataset.num_classes}")

# Modelo FCN-ResNet50
NUM_CLASSES = train_dataset.num_classes
model = fcn_resnet50(weights=None, num_classes=NUM_CLASSES).to(device)

criterion = nn.CrossEntropyLoss(ignore_index=255)
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# M√©tricas
def compute_mIoU(preds, labels, num_classes, ignore_index=255):
    ious = []
    valid_pixels = (labels != ignore_index)
    for cls in range(num_classes):
        pred_inds = (preds == cls) & valid_pixels
        label_inds = (labels == cls) & valid_pixels
        intersection = (pred_inds & label_inds).sum().item()
        union = (pred_inds | label_inds).sum().item()
        ious.append(np.nan if union == 0 else intersection / union)
    return np.nanmean(ious)

def accuracy(preds, labels, ignore_index=255):
    valid_pixels = (labels != ignore_index)
    correct = (preds == labels) & valid_pixels
    total = valid_pixels.sum().item()
    return np.nan if total == 0 else correct.sum().item() / total

# Hist√≥rico de m√©tricas
history = {"loss": [], "miou": [], "acc": []}

def train_model(num_epochs=5):
    print("\nIniciando treinamento...")
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for images, masks in train_loader:
            images, masks = images.to(device), masks.to(device)
            optimizer.zero_grad()
            outputs = model(images)['out']
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        # Avalia√ß√£o
        model.eval()
        miou_scores, acc_scores = [], []
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)['out']
                preds = torch.argmax(outputs, dim=1).cpu().numpy()
                labels = masks.cpu().numpy()
                for p, l in zip(preds, labels):
                    miou_scores.append(compute_mIoU(p, l, NUM_CLASSES))
                    acc_scores.append(accuracy(p, l))

        epoch_loss = running_loss / len(train_loader)
        epoch_miou = np.nanmean(miou_scores)
        epoch_acc = np.mean(acc_scores)
        print(f"üìå Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | mIoU: {epoch_miou:.4f} | Acc: {epoch_acc:.4f}")

        # Armazena e salva
        history["loss"].append(epoch_loss)
        history["miou"].append(epoch_miou)
        history["acc"].append(epoch_acc)
        torch.save(model.state_dict(), f'/content/drive/MyDrive/Cityscapes/fcn_epoch_{epoch+1}.pth')

    print("‚úÖ Treinamento finalizado.")

# Treina o modelo
train_model(num_epochs=5)

# Cria os gr√°fico
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.plot(history["loss"], marker='o'); plt.title("Loss"); plt.xlabel("Epoch"); plt.grid()
plt.subplot(1, 3, 2)
plt.plot(history["miou"], marker='o'); plt.title("mIoU"); plt.xlabel("Epoch"); plt.grid()
plt.subplot(1, 3, 3)
plt.plot(history["acc"], marker='o'); plt.title("Acur√°cia"); plt.xlabel("Epoch"); plt.grid()
plt.tight_layout(); plt.show()

# Colormap e visualiza√ß√£o/ predi√ß√£o do modelo
def apply_colormap(mask, num_classes=19):
    cmap = plt.get_cmap('tab20', num_classes)
    norm = colors.Normalize(vmin=0, vmax=num_classes-1)
    return cmap(norm(mask))

def visualizar_amostra(model, loader):
    model.eval()
    images, masks = next(iter(loader))
    images = images.to(device)
    with torch.no_grad():
        outputs = model(images)['out']
    preds = torch.argmax(outputs, dim=1).cpu()

    img_display = images[0].cpu().permute(1, 2, 0)
    img_display = img_display * 0.5 + 0.5
    img_display = np.clip(img_display, 0, 1)

    fig, axs = plt.subplots(1, 3, figsize=(18, 6))
    axs[0].imshow(img_display); axs[0].set_title("Imagem Original"); axs[0].axis('off')
    axs[1].imshow(apply_colormap(masks[0].numpy())); axs[1].set_title("M√°scara Real"); axs[1].axis('off')
    axs[2].imshow(apply_colormap(preds[0].numpy())); axs[2].set_title("Predi√ß√£o"); axs[2].axis('off')
    plt.tight_layout(); plt.show()

# Exibe resultado
visualizar_amostra(model, val_loader)